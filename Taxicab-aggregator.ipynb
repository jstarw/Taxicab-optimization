{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_region = { 12: 1, 88: 1, 87: 1, 209: 1, 45: 1, 231: 1, 261: 1, 13: 1, 158: 2, 249: 2, 113: 2, 114: 2, 79: 2, 4: 2, 232: 2, 148: 2, 144: 2, 211: 2, 125: 2, 246: 3, 50: 3, 48: 3, 68: 3, 90: 3, 186: 3, 100: 3, 230: 3, 163: 3, 161: 3, 164: 3, 234: 3, 107: 3, 170: 3, 162: 3, 229: 3, 233: 3, 137: 3, 224: 3, 143: 4, 142: 4, 239: 4, 238: 4, 151: 4, 24: 4, 75: 5, 236: 5, 263: 5, 262: 5, 140: 5, 141: 5, 237: 5, 166: 6, 41: 6, 74: 6, 42: 6, 152: 6, 116: 6, 244: 7, 120: 7, 243: 7, 127: 7, 128: 7,\n",
    "}\n",
    "valid_ids = id_to_region.keys()\n",
    "columns = ['weekday', 'hour', 'region', 'count', 'total_amount_sum', 'duration_min', 'duration_sum', 'duration_max']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_pickup(data_pickup):\n",
    "    # Filter all trips that start and end in the above regions\n",
    "    # Create a copy\n",
    "    data_pickup_filtered = chunk.copy()\n",
    "\n",
    "    # Initialize the list to record which region the origin is located\n",
    "    in_which_region_list = []\n",
    "\n",
    "    # Loop through each row\n",
    "    for i in range(0, len(data_pickup)):\n",
    "        in_which_region = -1 # Initialize with -1\n",
    "        if data_pickup[\"PULocationID\"][i] in valid_ids and data_pickup[\"PULocationID\"][i] == data_pickup[\"DOLocationID\"][i]:\n",
    "            in_which_region = id_to_region[data_pickup[\"PULocationID\"][i]]\n",
    "        in_which_region_list.append(in_which_region)\n",
    "    data_pickup_filtered['region'] = in_which_region_list\n",
    "    # Keep only those have real region indice\n",
    "    data_pickup_filtered = data_pickup_filtered[data_pickup_filtered.region != -1] \n",
    "    # Reset the indice\n",
    "    data_pickup_filtered = data_pickup_filtered.dropna(how='any').reset_index(drop=True)\n",
    "    return data_pickup_filtered\n",
    "\n",
    "\n",
    "def process_datetime(data_datetime):     \n",
    "    weekday_list = []\n",
    "    hour_list = []\n",
    "    duration_list = []\n",
    "    count = [1] * len(data_datetime)\n",
    "    \n",
    "    for i in range(len(data_datetime)):\n",
    "        start = pd.to_datetime(data_datetime[\"tpep_pickup_datetime\"][i])\n",
    "        end = pd.to_datetime(data_datetime[\"tpep_dropoff_datetime\"][i])\n",
    "        weekday_list.append(start.weekday())\n",
    "        hour_list.append(start.hour)\n",
    "        duration_list.append(int((end-start).total_seconds()))\n",
    "\n",
    "    data_datetime[\"weekday\"] = weekday_list\n",
    "    data_datetime[\"hour\"] = hour_list\n",
    "    data_datetime[\"duration\"] = duration_list\n",
    "    data_datetime[\"count\"] = count\n",
    "    return data_datetime\n",
    "\n",
    "\n",
    "def compute_average(to_compute):\n",
    "    df = to_compute.copy()\n",
    "    # Remove unuseful columns\n",
    "    df = df.drop(\n",
    "        [\n",
    "            \"PULocationID\", \n",
    "            \"DOLocationID\", \n",
    "            \"tpep_pickup_datetime\", \n",
    "            \"tpep_dropoff_datetime\", \n",
    "            \"VendorID\",\n",
    "            \"passenger_count\",\n",
    "            \"RatecodeID\",\n",
    "            \"store_and_fwd_flag\",\n",
    "            \"payment_type\",\n",
    "            \"fare_amount\",\n",
    "            \"extra\",\n",
    "            \"mta_tax\",\n",
    "            \"tip_amount\",\n",
    "            \"tolls_amount\",\n",
    "            \"improvement_surcharge\",\n",
    "        ],\n",
    "        1\n",
    "    )\n",
    "    # groupby\n",
    "    df = df.groupby([\"weekday\",\"hour\",\"region\"], as_index=False).agg(\n",
    "        {\"count\": \"count\", \"total_amount\": \"sum\", \"duration\": [\"min\", \"sum\", \"max\"]}\n",
    "    )\n",
    "    \n",
    "    # rename the columns\n",
    "    df.columns = columns\n",
    "    return df\n",
    "\n",
    "\n",
    "def process_pipeline(df, chunk, i):\n",
    "    chunk = filter_pickup(chunk)\n",
    "    chunk = process_datetime(chunk)\n",
    "    chunk = compute_average(chunk)\n",
    "    # combine chunk to df \n",
    "\n",
    "    if i == 0:\n",
    "        df = chunk\n",
    "    else:\n",
    "        df = pd.concat([df, chunk], ignore_index=True)\n",
    "        df = df.groupby([\"weekday\",\"hour\",\"region\"], as_index=False).agg(\n",
    "            {\n",
    "                \"count\": \"sum\", \n",
    "                \"total_amount_sum\": \"sum\", \n",
    "                \"duration_min\": \"min\", \n",
    "                \"duration_sum\": \"sum\", \n",
    "                \"duration_max\": \"max\",\n",
    "            }\n",
    "        )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations run: 0, rows read: 10000\n",
      "[3 2]\n",
      "   weekday hour region count total_amount duration             \n",
      "                       count          sum      min    sum   max\n",
      "0        2   22      5     1         6.96      232    232   232\n",
      "1        3    5      3     1         3.30       10     10    10\n",
      "2        3    5      4     1         4.80       92     92    92\n",
      "3        3    5      6     1         3.80       71     71    71\n",
      "4        3    6      1     3        19.60      128    678   330\n",
      "5        3    6      2     2        76.03       11    171   160\n",
      "6        3    6      3    33       297.43        3   6514   424\n",
      "7        3    6      4     5       137.06        5    336   175\n",
      "8        3    6      5    29       231.21       35   5480   497\n",
      "9        3    6      6     6        34.50       93   1479   475\n",
      "10       3    7      1    30       241.50       78  10944  1414\n",
      "11       3    7      2    27       196.75       28   8685  1656\n",
      "12       3    7      3   143      1176.28        5  37282  2635\n",
      "13       3    7      4    44       386.97       10  17596  2609\n",
      "14       3    7      5   152      1085.95        9  49777  1790\n",
      "15       3    7      6    23       168.52       41   8298  1203\n",
      "16       3    7      7     5        39.50       59   2312  1379\n",
      "17       3    8      2     3        60.90        2    118   109\n",
      "18       3    8      4     1         5.80      251    251   251\n",
      "saving to csv file data/2018_Taxi_Processed_2.csv\n"
     ]
    }
   ],
   "source": [
    "chunksize = 10 ** 5\n",
    "filename = \"data/2018_Yellow_Taxi_Trip_Data.csv\"\n",
    "output = \"data/2018_Taxi_Processed.csv\"\n",
    "current_size = 0\n",
    "i = 0\n",
    "df = pd.DataFrame(columns=columns)\n",
    "\n",
    "for chunk in pd.read_csv(filename, chunksize=chunksize):\n",
    "    current_size += len(chunk)\n",
    "    # reset indices\n",
    "    chunk = chunk.dropna(how='any').reset_index(drop=True)\n",
    "    print(\"Iterations run: %s, rows read: %s\" % (i, current_size))\n",
    "    df = process_pipeline(df, chunk, i)\n",
    "    i += 1\n",
    "\n",
    "# save to file\n",
    "print(\"saving to csv file %s\" % output)\n",
    "df.to_csv(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     4.897413\n",
      "1     5.394635\n",
      "2     6.112486\n",
      "3     9.600480\n",
      "4     8.922196\n",
      "5     6.549528\n",
      "6     9.650749\n",
      "7     3.867524\n",
      "8     3.794689\n",
      "9     6.538640\n",
      "10    5.940224\n",
      "11    9.144683\n",
      "12    4.422345\n",
      "13    8.063140\n",
      "14    2.763539\n",
      "15    6.933509\n",
      "16    5.487311\n",
      "17    9.333741\n",
      "18    9.530081\n",
      "19    5.141572\n",
      "20    9.100393\n",
      "21    1.964436\n",
      "22    8.832351\n",
      "23    5.469933\n",
      "24    9.317894\n",
      "25    4.096976\n",
      "26    8.758488\n",
      "27    9.398309\n",
      "28    6.895351\n",
      "29    3.885025\n",
      "        ...   \n",
      "70    6.559789\n",
      "71    5.432104\n",
      "72    5.783963\n",
      "73    8.308783\n",
      "74    7.332521\n",
      "75    4.268996\n",
      "76    7.925050\n",
      "77    4.211822\n",
      "78    6.758035\n",
      "79    5.858837\n",
      "80    7.604830\n",
      "81    6.215149\n",
      "82    8.693971\n",
      "83    6.998012\n",
      "84    5.372079\n",
      "85    4.898141\n",
      "86    6.374402\n",
      "87    6.447969\n",
      "88    6.670066\n",
      "89    6.588048\n",
      "90    8.041536\n",
      "91    7.260056\n",
      "92    7.994424\n",
      "93    5.630496\n",
      "94    7.395386\n",
      "95    7.102816\n",
      "96    8.724888\n",
      "97    8.122392\n",
      "98    7.413807\n",
      "99    7.463099\n",
      "Name: min_trips, Length: 100, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "output = (\"data/2018_Taxi_Aggregated.csv\")\n",
    "df = pd.read_csv(\"data/2018_Taxi_Processed.csv\")\n",
    "\n",
    "\"\"\"\n",
    "We need to calculate the following:\n",
    "\n",
    "Min, Average, Max number of trips (Cmin, C, Cmax) per hour per region\n",
    "Average duration of trip (D) per hour per region\n",
    "Average Fare of trip (F) per hour per region\n",
    "\"\"\" \n",
    "df[\"min_trips\"] = 3600/(df.duration_sum/df[\"count\"]+180)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
